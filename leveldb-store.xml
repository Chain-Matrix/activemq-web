<div class="wiki-content maincontent"><structured-macro ac:macro-id="835b8a22-754e-4802-be3d-f79767a2fd2c" ac:name="warning" ac:schema-version="1"><parameter ac:name="title">Warning</parameter><rich-text-body><p>The LevelDB store has been deprecated and is no longer supported or recommended for use. The recommended store is <link><page ri:content-title="KahaDB"></page></link></p></rich-text-body></structured-macro><structured-macro ac:macro-id="4241afc9-4931-47c2-a2a5-6bd1bd1f3e90" ac:name="info" ac:schema-version="1"><parameter ac:name="title">Version Compatibility</parameter><rich-text-body><p>Available in ActiveMQ 5.8.0 and newer</p></rich-text-body></structured-macro><p>The LevelDB Store is a file based persistence database that is local to the message broker that is using it. It has been optimized to provide even faster persistence than KahaDB. It's similar to KahahDB but instead of using a custom B-Tree implementation to index the write ahead logs, it uses <a shape="rect" href="https://code.google.com/p/leveldb/">LevelDB</a> based indexes which have several nice properties due to the 'append only' files access patterns :</p><ul><li>Fast updates (No need to do random disk updates)</li><li>Concurrent reads</li><li>Fast index snapshots using hard links</li></ul><p>Both KahaDB and the LevelDB store have to do periodic garbage collection cycles to determine which log files can deleted. In the case of KahaDB, this can be quite expensive as you increase the amount of data stored and can cause read/write stalls while the collection occurs. The LevelDB store uses a much cheaper algorithm to determine when log files can be collected and avoids those stalls.</p><h2>Configuration</h2><p>You can configure ActiveMQ to use LevelDB for its persistence adapter - like below :</p><structured-macro ac:macro-id="bc167008-ff01-4629-b82f-c04e071d6683" ac:name="code" ac:schema-version="1"><plain-text-body>  &lt;broker brokerName="broker" ... &gt;
    ...
    &lt;persistenceAdapter&gt;
      &lt;levelDB directory="activemq-data"/&gt;
    &lt;/persistenceAdapter&gt;
    ...
  &lt;/broker&gt;
</plain-text-body></structured-macro><h3>LevelDB Properties</h3><table><tbody><tr><th colspan="1" rowspan="1"><p>property name</p></th><th colspan="1" rowspan="1"><p>default value</p></th><th colspan="1" rowspan="1"><p>Comments</p></th></tr><tr><td colspan="1" rowspan="1"><p>directory</p></td><td colspan="1" rowspan="1"><p>"LevelDB"</p></td><td colspan="1" rowspan="1"><p>The directory which the store will use to hold it's data files. The store will create the directory if it does not already exist.</p></td></tr><tr><td colspan="1" rowspan="1"><p>sync</p></td><td colspan="1" rowspan="1"><p>true</p></td><td colspan="1" rowspan="1"><p>If set to false, then the store does not sync logging operations to disk</p></td></tr><tr><td colspan="1" rowspan="1"><p>logSize</p></td><td colspan="1" rowspan="1"><p>104857600 (100 MB)</p></td><td colspan="1" rowspan="1"><p>The max size (in bytes) of each data log file before log file rotation occurs.</p></td></tr><tr><td colspan="1" rowspan="1"><p>verifyChecksums</p></td><td colspan="1" rowspan="1"><p>false</p></td><td colspan="1" rowspan="1"><p>Set to true to force checksum verification of all data that is read from the file system.</p></td></tr><tr><td colspan="1" rowspan="1"><p>paranoidChecks</p></td><td colspan="1" rowspan="1"><p>false</p></td><td colspan="1" rowspan="1"><p>Make the store error out as soon as possible if it detects internal corruption.</p></td></tr><tr><td colspan="1" rowspan="1"><p>indexFactory</p></td><td colspan="1" rowspan="1"><p>org.fusesource.leveldbjni.JniDBFactory, org.iq80.leveldb.impl.Iq80DBFactory</p></td><td colspan="1" rowspan="1"><p>The factory classes to use when creating the LevelDB indexes</p></td></tr><tr><td colspan="1" rowspan="1"><p>indexMaxOpenFiles</p></td><td colspan="1" rowspan="1"><p>1000</p></td><td colspan="1" rowspan="1"><p>Number of open files that can be used by the index.</p></td></tr><tr><td colspan="1" rowspan="1"><p>indexBlockRestartInterval</p></td><td colspan="1" rowspan="1"><p>16</p></td><td colspan="1" rowspan="1"><p>Number keys between restart points for delta encoding of keys.</p></td></tr><tr><td colspan="1" rowspan="1"><p>indexWriteBufferSize</p></td><td colspan="1" rowspan="1"><p>6291456 (6 MB)</p></td><td colspan="1" rowspan="1"><p>Amount of index data to build up in memory before converting to a sorted on-disk file.</p></td></tr><tr><td colspan="1" rowspan="1"><p>indexBlockSize</p></td><td colspan="1" rowspan="1"><p>4096 (4 K)</p></td><td colspan="1" rowspan="1"><p>The size of index data packed per block.</p></td></tr><tr><td colspan="1" rowspan="1"><p>indexCacheSize</p></td><td colspan="1" rowspan="1"><p>268435456 (256 MB)</p></td><td colspan="1" rowspan="1"><p>The maximum amount of off-heap memory to use to cache index blocks.</p></td></tr><tr><td colspan="1" rowspan="1"><p>indexCompression</p></td><td colspan="1" rowspan="1"><p>snappy</p></td><td colspan="1" rowspan="1"><p>The type of compression to apply to the index blocks. Can be snappy or none.</p></td></tr><tr><td colspan="1" rowspan="1"><p>logCompression</p></td><td colspan="1" rowspan="1"><p>none</p></td><td colspan="1" rowspan="1"><p>The type of compression to apply to the log records. Can be snappy or none.</p></td></tr></tbody></table><p>For tuning locking properties please take a look at <link><page ri:content-title="Pluggable storage lockers"></page></link></p><h2>Also See</h2><ul><li><link><page ri:content-title="Replicated LevelDB Store"></page></link> An extended version of this store which self replicates to other broker nodes to increase message availability.</li></ul></div>

