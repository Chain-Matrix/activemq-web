<div class="wiki-content maincontent"><h2>How can I support priority queues?</h2>

<h3>Use Message Priority</h3>

<p>A common requirement is to support priority consumption; so high priority messages are consumed before low priority.</p>

<p>In version 5.4 priority queues are supported. Both the message cursors and the message stores (KahaDB and JDBC) support message priority. The support is disabled by default so it needs to be be enabled using <link><page ri:content-title="per destination policies"></page></link> through xml configuration, in the example below, 'prioritizedMessages' is enabled for all queues. </p>
<structured-macro ac:macro-id="d0404155-3918-434f-b576-8f72b792b667" ac:name="code" ac:schema-version="1"><plain-text-body>
 &lt;destinationPolicy&gt;
   &lt;policyMap&gt;
     &lt;policyEntries&gt;
       &lt;policyEntry queue="&gt;" prioritizedMessages="true"/&gt;
    ...
</plain-text-body></structured-macro>

<p>The full range of priority values (0-9) are supported by the <link><page ri:content-title="jdbc support"></page><link-body>JDBC</link-body></link> message store. For <link><page ri:content-title="KahaDB"></page></link> three priority categories are supported, Low (&lt; 4), Default (= 4) and High (&gt; 4).</p>

<p>Since the message cursors (and client side) implement strict ordering of priorities, it's possible to observe strict priority ordering if message dispatching can happen from the cache and not have to hit the disk (i.e., your consumers are fast enough to keep up with producers), or if you're using non-persistent messages that never have to flush to disk (using the FilePendingMessageCursor). However, once you hit a situation where consumers are slow, or producers are just significantly faster, you'll observe that the cache will fill up (possibly with lower priority messages) while higher priority messages get stuck on disk and not available until they're paged in. In this case, you can make a decision to tradeoff optimized message dispatching for priority enforcement. You can disable the cache, message expiration check, and lower you consumer prefetch to 1 to ensure getting the high priority messages from the store ahead of lower priority messages Note, this sort of tradeoff can have significant performance implications, so you must test your scenarios thoroughly. :</p>


<structured-macro ac:macro-id="11e4935d-0104-4709-a871-c3467bedb529" ac:name="code" ac:schema-version="1"><plain-text-body>
 &lt;destinationPolicy&gt;
   &lt;policyMap&gt;
     &lt;policyEntries&gt;
       &lt;policyEntry queue="&gt;" prioritizedMessages="true" useCache="false" expireMessagesPeriod="0" queuePrefetch="1" /&gt;
    ...
</plain-text-body></structured-macro>

<h3>Alternative strategies</h3>
<h4>Use Selectors</h4>

<p>You can have say 100 consumers using a selector to find the high priority stuff</p>

<structured-macro ac:macro-id="ce5db972-0df5-47c1-92be-39bf60b456f7" ac:name="code" ac:schema-version="1"><plain-text-body>
JMSPriority &gt; 6
</plain-text-body></structured-macro>

<p>then have 50 consumers doing average or above</p>

<structured-macro ac:macro-id="0fc1e06f-98b9-4e33-8552-2e3bd2cfa13e" ac:name="code" ac:schema-version="1"><plain-text-body>
JMSPriority &gt;= 4
</plain-text-body></structured-macro>

<p>Then say 10 consumers consuming all messages (so all priorities). Then this way you'll have a pool of threads always processing high priority messages - giving you very efficient priority based dispatching of messages without ActiveMQ having to batch up messages and reorder them before dispatching them.</p>

<h4>Use Resequencer</h4>

<p>You can reorder messages on some input queue A and send them to queue B in sorted order to avoid having to change your clients. This avoids the need to use selectors in your application as shown above.</p>

<p>To do this use the <a shape="rect" href="http://activemq.apache.org/camel/resequencer.html">Resequencer</a> from the <link><page ri:content-title="Enterprise Integration Patterns"></page></link></p></div>

